{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf649c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cairo\n",
    "import cv2\n",
    "from math import pi\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42fb30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_to_cart(theta, dist):\n",
    "    \n",
    "    x = 1 + dist * math.cos(theta)\n",
    "    y = 1 + dist * math.sin(theta)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "t = math.pi/180.0\n",
    "\n",
    "def remap(old_val, old_min, old_max, new_min, new_max):\n",
    "    return (new_max - new_min)*(old_val - old_min) / (old_max - old_min) + new_min\n",
    "\n",
    "def make_hashable(array):\n",
    "    return tuple(map(float, array))\n",
    "\n",
    "\n",
    "def draw(geno):\n",
    "    \n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, 100, 100)\n",
    "    ctx = cairo.Context(surface)\n",
    "    #ctx.set_antialias(cairo.ANTIALIAS_NONE)\n",
    "\n",
    "    ctx.scale(50, 50)\n",
    "    # Paint the background\n",
    "    ctx.set_source_rgb(0, 0 , 0)\n",
    "    ctx.paint()\n",
    "\n",
    "    r1 = remap(geno[8], 0, 1,0.1, 1)\n",
    "    r2 = remap(geno[9], 0, 1,0.1, 1)\n",
    "    r3 = remap(geno[10], 0, 1,0.1, 1)\n",
    "    r4 = remap(geno[11], 0, 1,0.1, 1)\n",
    "    r5 = remap(geno[12], 0, 1,0.1, 1)\n",
    "    r6 = remap(geno[13], 0, 1,0.1, 1)\n",
    "    r7 = remap(geno[14], 0, 1,0.1, 1)\n",
    "    r8 = remap(geno[15], 0, 1,0.1, 1)\n",
    "\n",
    "    # Draw the image\n",
    "    firstx, firsty = polar_to_cart((0 + geno[0])*45*t, r1)\n",
    "    secondx, secondy = polar_to_cart((1 + geno[1])*45*t, r2)\n",
    "    thirdx, thirdy = polar_to_cart((2 + geno[2])*45*t, r3)\n",
    "    forthx, forthy = polar_to_cart((3 + geno[3])*45*t, r4)\n",
    "    fifthx, fifthy = polar_to_cart((4 + geno[4])*45*t, r5)\n",
    "    sixthx, sixthy = polar_to_cart((5 + geno[5])*45*t, r6)\n",
    "    seventhx, seventhy = polar_to_cart((6 + geno[6])*45*t, r7)\n",
    "    eigthx, eigthy = polar_to_cart((7 + geno[7])*45*t, r8)\n",
    "    ctx.move_to(firstx, firsty)\n",
    "\n",
    "    ctx.line_to(secondx, secondy)\n",
    "    ctx.line_to(thirdx, thirdy)\n",
    "    ctx.line_to(forthx, forthy)\n",
    "    ctx.line_to(fifthx, fifthy)\n",
    "    ctx.line_to(sixthx, sixthy)\n",
    "    ctx.line_to(seventhx, seventhy)\n",
    "    ctx.line_to(eigthx, eigthy)\n",
    "    \n",
    "    ctx.close_path()\n",
    "    ctx.set_source_rgb(1, 1, 1)\n",
    "    ctx.fill_preserve()\n",
    "    \n",
    "\n",
    "    return surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93aa5069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread avg3 : 0.06541838046272486\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_avg3.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_avg3 = []\n",
    "spread_avg3 = []\n",
    "\n",
    "centroids_avg3 = load_centroids(\"centroids_avg3.dat\")\n",
    "data_avg3 = np.loadtxt(\"archive_avg3.dat\")\n",
    "fit_avg3 = data_avg3[:,0:1]\n",
    "cent_avg3 = data_avg3[:, 1:3]\n",
    "desc_avg3 = data_avg3[:, 3: 5]\n",
    "geno_avg3 = data_avg3[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_avg3 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_avg3.shape[0]):\n",
    "    archive[tuple(cent_avg3[j])] = [geno_avg3[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_avg3.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_avg3[i][0], desc_avg3[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten()\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten()\n",
    "        dist = distance.hamming(flat1,flat2)\n",
    "        distances.append(dist)\n",
    "    except:\n",
    "        pass\n",
    "spread_avg3 = sum(distances)/len(distances)\n",
    "print(\"Spread avg3 : {}\".format(spread_avg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e8b5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread avg7 : 0.0574322250639386\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_avg7.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_avg7 = []\n",
    "spread_avg7 = []\n",
    "\n",
    "centroids_avg7 = load_centroids(\"centroids_avg7.dat\")\n",
    "data_avg7 = np.loadtxt(\"archive_avg7.dat\")\n",
    "fit_avg7 = data_avg7[:,0:1]\n",
    "cent_avg7 = data_avg7[:, 1:3]\n",
    "desc_avg7 = data_avg7[:, 3: 5]\n",
    "geno_avg7 = data_avg7[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_avg7 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_avg7.shape[0]):\n",
    "    archive[tuple(cent_avg7[j])] = [geno_avg7[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_avg7.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_avg7[i][0], desc_avg7[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten()\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten()\n",
    "        dist = distance.hamming(flat1,flat2)\n",
    "        distances.append(dist)\n",
    "    except:\n",
    "        pass\n",
    "spread_avg7 = sum(distances)/len(distances)\n",
    "print(\"Spread avg7 : {}\".format(spread_avg7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebebc15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread myversion3 : 0.04873602564102563\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_myversion3.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_myversion3 = []\n",
    "spread_myversion3 = []\n",
    "\n",
    "centroids_myversion3 = load_centroids(\"centroids_myversion3.dat\")\n",
    "data_myversion3 = np.loadtxt(\"archive_myversion3.dat\")\n",
    "fit_myversion3 = data_myversion3[:,0:1]\n",
    "cent_myversion3 = data_myversion3[:, 1:3]\n",
    "desc_myversion3 = data_myversion3[:, 3: 5]\n",
    "geno_myversion3 = data_myversion3[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_myversion3 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_myversion3.shape[0]):\n",
    "    archive[tuple(cent_myversion3[j])] = [geno_myversion3[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_myversion3.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_myversion3[i][0], desc_myversion3[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten()\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten()\n",
    "        dist = distance.hamming(flat1,flat2)\n",
    "        distances.append(dist)\n",
    "    except:\n",
    "        pass\n",
    "spread_myversion3 = sum(distances)/len(distances)\n",
    "print(\"Spread myversion3 : {}\".format(spread_myversion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "087400dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread myversion7 : 0.05066044098573278\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_myversion7.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_myversion7 = []\n",
    "spread_myversion7 = []\n",
    "\n",
    "centroids_myversion7 = load_centroids(\"centroids_myversion7.dat\")\n",
    "data_myversion7 = np.loadtxt(\"archive_myversion7.dat\")\n",
    "fit_myversion7 = data_myversion7[:,0:1]\n",
    "cent_myversion7 = data_myversion7[:, 1:3]\n",
    "desc_myversion7 = data_myversion7[:, 3: 5]\n",
    "geno_myversion7 = data_myversion7[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_myversion7 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_myversion7.shape[0]):\n",
    "    archive[tuple(cent_myversion7[j])] = [geno_myversion7[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_myversion7.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_myversion7[i][0], desc_myversion7[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten()\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten()\n",
    "        dist = distance.hamming(flat1,flat2)\n",
    "        distances.append(dist)\n",
    "    except:\n",
    "        pass\n",
    "spread_myversion7 = sum(distances)/len(distances)\n",
    "print(\"Spread myversion7 : {}\".format(spread_myversion7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b94ea024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread standard : 0.07719770408163257\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_standard.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_standard = []\n",
    "spread_standard = []\n",
    "\n",
    "centroids_standard = load_centroids(\"centroids_standard.dat\")\n",
    "data_standard = np.loadtxt(\"archive_standard.dat\")\n",
    "fit_standard = data_standard[:,0:1]\n",
    "cent_standard = data_standard[:, 1:3]\n",
    "desc_standard = data_standard[:, 3: 5]\n",
    "geno_standard = data_standard[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_standard = []\n",
    "archive = {}\n",
    "for j in range(0, fit_standard.shape[0]):\n",
    "    archive[tuple(cent_standard[j])] = [geno_standard[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_standard.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_standard[i][0], desc_standard[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten()\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten()\n",
    "        dist = distance.hamming(flat1,flat2)\n",
    "        distances.append(dist)\n",
    "    except:\n",
    "        pass\n",
    "spread_standard = sum(distances)/len(distances)\n",
    "print(\"Spread standard : {}\".format(spread_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "014ddb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Spread standard Euclidean : 0.1978581688149776\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_standard.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_standard = []\n",
    "spread_standard = []\n",
    "\n",
    "t1 = np.zeros(10000)\n",
    "t2 = np.ones(10000)\n",
    "max_d = np.linalg.norm(t1 - t2)\n",
    "print(max_d)\n",
    "\n",
    "centroids_standard = load_centroids(\"centroids_standard.dat\")\n",
    "data_standard = np.loadtxt(\"archive_standard.dat\")\n",
    "fit_standard = data_standard[:,0:1]\n",
    "cent_standard = data_standard[:, 1:3]\n",
    "desc_standard = data_standard[:, 3: 5]\n",
    "geno_standard = data_standard[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_standard = []\n",
    "archive = {}\n",
    "for j in range(0, fit_standard.shape[0]):\n",
    "    archive[tuple(cent_standard[j])] = [geno_standard[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_standard.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_standard[i][0], desc_standard[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten() / 255\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten() / 255\n",
    "        dist = np.linalg.norm(flat1 - flat2)\n",
    "        distances.append(dist / max_d)\n",
    "    except:\n",
    "        pass\n",
    "spread_standard = sum(distances)/len(distances)\n",
    "print(\"Spread standard Euclidean : {}\".format(spread_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8492f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Spread avg3 Euclidean : 0.1734434500285052\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_avg3.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_avg3 = []\n",
    "spread_avg3 = []\n",
    "\n",
    "t1 = np.zeros(10000)\n",
    "t2 = np.ones(10000)\n",
    "max_d = np.linalg.norm(t1 - t2)\n",
    "print(max_d)\n",
    "\n",
    "centroids_avg3 = load_centroids(\"centroids_avg3.dat\")\n",
    "data_avg3 = np.loadtxt(\"archive_avg3.dat\")\n",
    "fit_avg3 = data_avg3[:,0:1]\n",
    "cent_avg3 = data_avg3[:, 1:3]\n",
    "desc_avg3 = data_avg3[:, 3: 5]\n",
    "geno_avg3 = data_avg3[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_avg3 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_avg3.shape[0]):\n",
    "    archive[tuple(cent_avg3[j])] = [geno_avg3[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_avg3.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_avg3[i][0], desc_avg3[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten() / 255\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten() / 255\n",
    "        dist = np.linalg.norm(flat1 - flat2)\n",
    "        distances.append(dist / max_d)\n",
    "    except:\n",
    "        pass\n",
    "spread_avg3 = sum(distances)/len(distances)\n",
    "print(\"Spread avg3 Euclidean : {}\".format(spread_avg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb1b550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Spread avg7 Euclidean : 0.1552195442887115\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_avg7.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_avg7 = []\n",
    "spread_avg7 = []\n",
    "\n",
    "t1 = np.zeros(10000)\n",
    "t2 = np.ones(10000)\n",
    "max_d = np.linalg.norm(t1 - t2)\n",
    "print(max_d)\n",
    "\n",
    "centroids_avg7 = load_centroids(\"centroids_avg7.dat\")\n",
    "data_avg7 = np.loadtxt(\"archive_avg7.dat\")\n",
    "fit_avg7 = data_avg7[:,0:1]\n",
    "cent_avg7 = data_avg7[:, 1:3]\n",
    "desc_avg7 = data_avg7[:, 3: 5]\n",
    "geno_avg7 = data_avg7[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_avg7 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_avg7.shape[0]):\n",
    "    archive[tuple(cent_avg7[j])] = [geno_avg7[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_avg7.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_avg7[i][0], desc_avg7[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten() / 255\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten() / 255\n",
    "        dist = np.linalg.norm(flat1 - flat2)\n",
    "        distances.append(dist / max_d)\n",
    "    except:\n",
    "        pass\n",
    "spread_avg7 = sum(distances)/len(distances)\n",
    "print(\"Spread avg7 Euclidean : {}\".format(spread_avg7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff9122f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Spread myversion3 Euclidean : 0.136213573943734\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_myversion3.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_myversion3 = []\n",
    "spread_myversion3 = []\n",
    "\n",
    "t1 = np.zeros(10000)\n",
    "t2 = np.ones(10000)\n",
    "max_d = np.linalg.norm(t1 - t2)\n",
    "print(max_d)\n",
    "\n",
    "centroids_myversion3 = load_centroids(\"centroids_myversion3.dat\")\n",
    "data_myversion3 = np.loadtxt(\"archive_myversion3.dat\")\n",
    "fit_myversion3 = data_myversion3[:,0:1]\n",
    "cent_myversion3 = data_myversion3[:, 1:3]\n",
    "desc_myversion3 = data_myversion3[:, 3: 5]\n",
    "geno_myversion3 = data_myversion3[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_myversion3 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_myversion3.shape[0]):\n",
    "    archive[tuple(cent_myversion3[j])] = [geno_myversion3[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_myversion3.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_myversion3[i][0], desc_myversion3[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten() / 255\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten() / 255\n",
    "        dist = np.linalg.norm(flat1 - flat2)\n",
    "        distances.append(dist / max_d)\n",
    "    except:\n",
    "        pass\n",
    "spread_myversion3 = sum(distances)/len(distances)\n",
    "print(\"Spread myversion3 Euclidean : {}\".format(spread_myversion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88fa26a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Spread myversion7 Euclidean : 0.13517269709154908\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, dim,dim_x):\n",
    "    print(\"Loading \",filename)\n",
    "    data = np.loadtxt(filename)\n",
    "    fit = data[:, 0:1]\n",
    "    cent = data[:,1: dim+1]\n",
    "    desc = data[:,dim+1: 2*dim+1]\n",
    "    x = data[:,2*dim+1:2*dim+1+dim_x]\n",
    "    \n",
    "def load_centroids(filename):\n",
    "    points = np.loadtxt(filename)\n",
    "    return points\n",
    "\n",
    "def getKDT(n_niches, dim_map):\n",
    "\n",
    "    fname = \"centroids_myversion7.dat\"\n",
    "    c = np.loadtxt(fname)\n",
    "    kdt = KDTree(c, leaf_size=30, metric='euclidean')\n",
    "    return kdt\n",
    "\n",
    "diversity_myversion7 = []\n",
    "spread_myversion7 = []\n",
    "\n",
    "t1 = np.zeros(10000)\n",
    "t2 = np.ones(10000)\n",
    "max_d = np.linalg.norm(t1 - t2)\n",
    "print(max_d)\n",
    "\n",
    "centroids_myversion7 = load_centroids(\"centroids_myversion7.dat\")\n",
    "data_myversion7 = np.loadtxt(\"archive_myversion7.dat\")\n",
    "fit_myversion7 = data_myversion7[:,0:1]\n",
    "cent_myversion7 = data_myversion7[:, 1:3]\n",
    "desc_myversion7 = data_myversion7[:, 3: 5]\n",
    "geno_myversion7 = data_myversion7[:, 5: 21]\n",
    "#print(\"Fit: {}\".format(fit[1]))\n",
    "#print(\"Cent: {}\".format(cent[1]))\n",
    "#print(\"Behavior: {}\".format(desc[1]))\n",
    "#print(\"Geno: {}\".format(geno[1]))\n",
    "\n",
    "#Spread \n",
    "spread_myversion7 = []\n",
    "archive = {}\n",
    "for j in range(0, fit_myversion7.shape[0]):\n",
    "    archive[tuple(cent_myversion7[j])] = [geno_myversion7[j]]\n",
    "\n",
    "kdt = getKDT(1000, 2)\n",
    "distances = []\n",
    "for i in range(0, fit_myversion7.shape[0]):\n",
    "    try:\n",
    "        test = kdt.query([np.array([desc_myversion7[i][0], desc_myversion7[i][1]])], k=2)[1][0]\n",
    "        niche_1= kdt.data[test[0]]\n",
    "        niche_2= kdt.data[test[1]]\n",
    "        n1 = make_hashable(niche_1)\n",
    "        n2 = make_hashable(niche_2)\n",
    "        uno = np.array(archive[n1][0])\n",
    "        due = np.array(archive[n2][0])\n",
    "\n",
    "        img1 = draw(uno)\n",
    "        imgP1 = Image.frombuffer(\"RGBA\",( img1.get_width(),img1.get_height() ),img1.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr1 = np.array(imgP1)\n",
    "        flat1 = img_arr1[:,:,0].flatten() / 255\n",
    "        img2 = draw(due)\n",
    "        imgP2 = Image.frombuffer(\"RGBA\",( img2.get_width(),img2.get_height() ),img2.get_data(),\"raw\",\"RGBA\",0,1)\n",
    "        img_arr2 = np.array(imgP2)\n",
    "        flat2 = img_arr2[:,:,0].flatten() / 255\n",
    "        dist = np.linalg.norm(flat1 - flat2)\n",
    "        distances.append(dist / max_d)\n",
    "    except:\n",
    "        pass\n",
    "spread_myversion7 = sum(distances)/len(distances)\n",
    "print(\"Spread myversion7 Euclidean : {}\".format(spread_myversion7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb03e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67558e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
